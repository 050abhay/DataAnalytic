{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e852fa11-06ce-4fce-b58e-aa77b907d807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nbformat as nbf\n",
    "\n",
    "# Create a new notebook object\n",
    "nb = nbf.v4.new_notebook()\n",
    "\n",
    "# Define the text content with mixed markdown and code\n",
    "text_content = [\n",
    "    (\"markdown\", \"# Pandas Series: Overview\\n1. A Pandas Series is a one-dimensional labeled array capable of holding any data type, including integers, floats, strings, Python objects, and more.\\n2. It can be thought of as a single column in a spreadsheet or a single column of a DataFrame.\\n3. Each element in a Series has an associated label or index, which allows for fast and easy data retrieval.\"),\n",
    "    \n",
    "    (\"markdown\", \"## Key Features of a Pandas Series\\n1. **Homogeneous Data**: All elements in a Series are of the same data type.\\n2. **Labeled Index**: Each element is associated with an index, which is a label that allows you to access elements by their index rather than their position.\\n3. **Automatic Alignment**: Series objects align automatically based on their index when performing operations.\\n4. **Flexible Indexing**: Series supports both integer and label-based indexing.\"),\n",
    "    \n",
    "    (\"markdown\", \"## Creating a Pandas Series\\nThere are several ways to create a Pandas Series:\"),\n",
    "    \n",
    "    (\"markdown\", \"### 1. From a Python List:\"),\n",
    "    (\"code\", \"\"\"import pandas as pd\n",
    "\n",
    "data = [10, 20, 30, 40]\n",
    "s = pd.Series(data)\n",
    "print(s)\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\n0    10\\n1    20\\n2    30\\n3    40\\ndtype: int64\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"### 2. From a Dictionary:\"),\n",
    "    (\"code\", \"\"\"data = {'a': 10, 'b': 20, 'c': 30, 'd': 40}\n",
    "s = pd.Series(data)\n",
    "print(s)\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\na    10\\nb    20\\nc    30\\nd    40\\ndtype: int64\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"### 3. From a Scalar Value:\\nYou can create a Series with the same value repeated across a specified index.\"),\n",
    "    (\"code\", \"\"\"s = pd.Series(5, index=['a', 'b', 'c', 'd'])\n",
    "print(s)\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\na    5\\nb    5\\nc    5\\nd    5\\ndtype: int64\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"### 4. Custom Indexing:\\nYou can provide a custom index while creating a Series.\"),\n",
    "    (\"code\", \"\"\"data = [10, 20, 30, 40]\n",
    "s = pd.Series(data, index=['a', 'b', 'c', 'd'])\n",
    "print(s)\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\na    10\\nb    20\\nc    30\\nd    40\\ndtype: int64\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"## Accessing Data in a Series\"),\n",
    "    \n",
    "    (\"markdown\", \"### 1. By Index Label:\\n**Accessing a single element:**\"),\n",
    "    (\"code\", \"\"\"print(s['b'])\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\n20\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"### Accessing multiple elements:\"),\n",
    "    (\"code\", \"\"\"print(s[['a', 'c']])\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\na    10\\nc    30\\ndtype: int64\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"### 2. By Integer Location:\\n**Accessing a single element:**\"),\n",
    "    (\"code\", \"\"\"print(s[1])\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\n20\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"### Accessing a range of elements:\"),\n",
    "    (\"code\", \"\"\"print(s[1:3])\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\nb    20\\nc    30\\ndtype: int64\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"## Vectorized Operations on Series\\nOne of the powerful features of Pandas is the ability to perform vectorized operations on Series, which means applying an operation to each element in the Series without the need for explicit loops.\"),\n",
    "    \n",
    "    (\"markdown\", \"### 1. Arithmetic Operations:\"),\n",
    "    (\"code\", \"\"\"s = pd.Series([1, 2, 3, 4])\n",
    "print(s + 10)\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\n0    11\\n1    12\\n2    13\\n3    14\\ndtype: int64\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"### 2. Element-wise Operations:\"),\n",
    "    (\"code\", \"\"\"s = pd.Series([1, 2, 3, 4])\n",
    "print(s * s)\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\n0     1\\n1     4\\n2     9\\n3    16\\ndtype: int64\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"### 3. Using NumPy Functions:\"),\n",
    "    (\"code\", \"\"\"import numpy as np\n",
    "s = pd.Series([1, 2, 3, 4])\n",
    "print(np.exp(s))\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\n0     2.718282\\n1     7.389056\\n2    20.085537\\n3    54.598150\\ndtype: float64\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"## Handling Missing Data in Series\\nPandas Series has built-in support for handling missing data using NaN (Not a Number).\"),\n",
    "    \n",
    "    (\"markdown\", \"### 1. Creating a Series with Missing Data:\"),\n",
    "    (\"code\", \"\"\"s = pd.Series([1, 2, np.nan, 4])\n",
    "print(s)\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\n0    1.0\\n1    2.0\\n2    NaN\\n3    4.0\\ndtype: float64\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"### 2. Detecting Missing Data:\"),\n",
    "    (\"code\", \"\"\"print(s.isnull())\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\n0    False\\n1    False\\n2     True\\n3    False\\ndtype: bool\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"### 3. Filling Missing Data:\"),\n",
    "    (\"code\", \"\"\"print(s.fillna(0))\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\n0    1.0\\n1    2.0\\n2    0.0\\n3    4.0\\ndtype: float64\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"### 4. Dropping Missing Data:\"),\n",
    "    (\"code\", \"\"\"print(s.dropna())\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\n0    1.0\\n1    2.0\\n3    4.0\\ndtype: float64\\n```\"),\n",
    "    \n",
    "    (\"markdown\", \"## Example: Creating and Manipulating a Series\\nLetâ€™s consider a practical example where we create a Series of exam scores and perform some operations.\"),\n",
    "    \n",
    "    (\"code\", \"\"\"import pandas as pd\n",
    "\n",
    "# Create a Series with custom index\n",
    "scores = pd.Series([85, 90, 78, 92, 88], index=['Alice', 'Bob', 'Charlie', 'David', 'Eva'])\n",
    "\n",
    "# Display the Series\n",
    "print(\"Scores:\")\n",
    "print(scores)\n",
    "\n",
    "# Accessing a single score\n",
    "print(\"\\\\nBob's score:\", scores['Bob'])\n",
    "\n",
    "# Calculating the average score\n",
    "average_score = scores.mean()\n",
    "print(\"\\\\nAverage score:\", average_score)\n",
    "\n",
    "# Adding 5 bonus points to all scores\n",
    "bonus_scores = scores + 5\n",
    "print(\"\\\\nScores after adding bonus points:\")\n",
    "print(bonus_scores)\n",
    "\n",
    "# Identify students who scored above 90 after the bonus\n",
    "high_scorers = bonus_scores[bonus_scores > 90]\n",
    "print(\"\\\\nStudents scoring above 90 after bonus:\")\n",
    "print(high_scorers)\n",
    "\"\"\"),\n",
    "    (\"markdown\", \"Output:\\n```\\nScores:\\nAlice      85\\nBob        90\\nCharlie    78\\nDavid      92\\nEva        88\\ndtype: int64\\n\\nBob's score: 90\\n\\nAverage score: 86.6\\n\\nScores after adding bonus points:\\nAlice      90\\nBob        95\\nCharlie    83\\nDavid      97\\nEva        93\\ndtype: int64\\n\\nStudents scoring above 90 after bonus:\\nBob       95\\nDavid     97\\nEva       93\\ndtype: int64\\n```\")\n",
    "]\n",
    "\n",
    "# Convert each section into markdown or code cells\n",
    "cells = []\n",
    "for cell_type, content in text_content:\n",
    "    if cell_type == \"code\":\n",
    "        cells.append(nbf.v4.new_code_cell(content.strip()))\n",
    "    else:\n",
    "        cells.append(nbf.v4.new_markdown_cell(content))\n",
    "\n",
    "# Assign the cells to the notebook\n",
    "nb['cells'] = cells\n",
    "\n",
    "# Write the notebook to a file with UTF-8 encoding\n",
    "with open('series.ipynb', 'w', encoding='utf-8') as f:\n",
    "    nbf.write(nb, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb869edc-d3a0-4874-ad5b-06904a42821b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 'pandas_groupby_example.ipynb' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import nbformat as nbf\n",
    "\n",
    "# Create a new notebook\n",
    "nb = nbf.v4.new_notebook()\n",
    "\n",
    "# Define the content of the notebook in Markdown and code cells\n",
    "cells = [\n",
    "    # Title and Introduction\n",
    "    nbf.v4.new_markdown_cell(\"# pandas.DataFrame.groupby\\n\"\n",
    "                             \"The pandas.DataFrame.groupby function is one of the most powerful features in pandas, used for grouping data based on one or more keys and then applying some aggregation, transformation, or other operations on those groups.\"\n",
    "    ),\n",
    "    \n",
    "    # Basic Concept\n",
    "    nbf.v4.new_markdown_cell(\"## 1. Basic Concept\\n\"\n",
    "                             \"DataFrame.groupby is similar to the SQL GROUP BY clause. It allows you to split the DataFrame into groups based on some criteria, perform operations on each group, and then combine the results back into a single DataFrame or Series.\"\n",
    "    ),\n",
    "    \n",
    "    # Syntax\n",
    "    nbf.v4.new_markdown_cell(\"## 2. Syntax\\n\\n\"\n",
    "                             \"```python\\n\"\n",
    "                             \"DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=NoDefault.no_default, observed=False, dropna=True)\\n\"\n",
    "                             \"```\\n\"\n",
    "    ),\n",
    "    \n",
    "    # Steps in Using groupby\n",
    "    nbf.v4.new_markdown_cell(\"## 3. Steps in Using groupby\\n\"\n",
    "                             \"1. **Splitting**: The data is split into groups based on the values of the specified key(s).\\n\"\n",
    "                             \"2. **Applying**: An operation is applied to each group independently. These operations can include:\\n\"\n",
    "                             \"   - Aggregation: e.g., sum, mean, count, etc.\\n\"\n",
    "                             \"   - Transformation: e.g., standardizing data within groups.\\n\"\n",
    "                             \"   - Filtration: e.g., filtering groups based on a condition.\\n\"\n",
    "                             \"3. **Combining**: The results are combined back into a DataFrame or Series.\"\n",
    "    ),\n",
    "    \n",
    "    # Common Aggregations\n",
    "    nbf.v4.new_markdown_cell(\"## 4. Common Aggregations\\n\"\n",
    "                             \"Here are some common aggregation functions you can use after grouping:\"\n",
    "    ),\n",
    "    \n",
    "    # Example 1\n",
    "    nbf.v4.new_markdown_cell(\"## 5. Examples\\n\\n\"\n",
    "                             \"### Example 1: Basic Grouping and Aggregation\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"import pandas as pd\\n\\n\"\n",
    "                         \"# Sample DataFrame\\n\"\n",
    "                         \"data = {\\n\"\n",
    "                         \"    'Category': ['A', 'B', 'A', 'B', 'A', 'B'],\\n\"\n",
    "                         \"    'Values': [10, 20, 15, 25, 10, 30]\\n\"\n",
    "                         \"}\\n\"\n",
    "                         \"df = pd.DataFrame(data)\\n\\n\"\n",
    "                         \"# Group by 'Category' and sum the 'Values'\\n\"\n",
    "                         \"grouped = df.groupby('Category').sum()\\n\\n\"\n",
    "                         \"print(grouped)\\n\"\n",
    "    ),\n",
    "    nbf.v4.new_markdown_cell(\"â€¢ Explanation: The DataFrame is grouped by the Category column, and the sum() function is applied to the Values column. This results in a new DataFrame where the Values for each Category are summed.\"\n",
    "    ),\n",
    "    \n",
    "    # Example 2\n",
    "    nbf.v4.new_markdown_cell(\"### Example 2: Grouping by Multiple Columns\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"data = {\\n\"\n",
    "                         \"    'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\\n\"\n",
    "                         \"    'Sub-Category': ['X', 'Y', 'X', 'Y', 'X', 'Y'],\\n\"\n",
    "                         \"    'Values': [1, 2, 3, 4, 5, 6]\\n\"\n",
    "                         \"}\\n\"\n",
    "                         \"df = pd.DataFrame(data)\\n\\n\"\n",
    "                         \"# Group by 'Category' and 'Sub-Category', then calculate the mean of 'Values'\\n\"\n",
    "                         \"grouped = df.groupby(['Category', 'Sub-Category']).mean()\\n\\n\"\n",
    "                         \"print(grouped)\\n\"\n",
    "    ),\n",
    "    nbf.v4.new_markdown_cell(\"â€¢ Explanation: The DataFrame is grouped by both Category and Sub-Category. The mean() function is applied to the Values column, giving the mean for each combination of Category and Sub-Category.\"\n",
    "    ),\n",
    "    \n",
    "    # Example 3\n",
    "    nbf.v4.new_markdown_cell(\"### Example 3: Grouping and Applying Multiple Aggregations\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"data = {\\n\"\n",
    "                         \"    'Category': ['A', 'A', 'B', 'B', 'A', 'B'],\\n\"\n",
    "                         \"    'Values': [10, 20, 15, 25, 10, 30]\\n\"\n",
    "                         \"}\\n\"\n",
    "                         \"df = pd.DataFrame(data)\\n\\n\"\n",
    "                         \"# Group by 'Category' and apply multiple aggregation functions\\n\"\n",
    "                         \"grouped = df.groupby('Category')['Values'].agg(['sum', 'mean', 'count'])\\n\\n\"\n",
    "                         \"print(grouped)\\n\"\n",
    "    ),\n",
    "    nbf.v4.new_markdown_cell(\"â€¢ Explanation: The DataFrame is grouped by the Category column, and multiple aggregation functions (sum, mean, and count) are applied to the Values column. The result is a new DataFrame with the specified aggregations.\"\n",
    "    ),\n",
    "    \n",
    "    # Example 4\n",
    "    nbf.v4.new_markdown_cell(\"### Example 4: Grouping and Filtering\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"data = {\\n\"\n",
    "                         \"    'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\\n\"\n",
    "                         \"    'Values': [10, 20, 10, 30, 50, 60]\\n\"\n",
    "                         \"}\\n\"\n",
    "                         \"df = pd.DataFrame(data)\\n\\n\"\n",
    "                         \"# Group by 'Category' and filter groups where the sum of 'Values' > 50\\n\"\n",
    "                         \"filtered = df.groupby('Category').filter(lambda x: x['Values'].sum() > 50)\\n\\n\"\n",
    "                         \"print(filtered)\\n\"\n",
    "    ),\n",
    "    nbf.v4.new_markdown_cell(\"â€¢ Explanation: The DataFrame is grouped by the Category column. The filter() function keeps only those groups where the sum of Values is greater than 50. In this case, only category 'C' meets the condition.\"\n",
    "    ),\n",
    "    \n",
    "    # Advanced Usage\n",
    "    nbf.v4.new_markdown_cell(\"## 6. Advanced Usage\\n\\n\"\n",
    "                             \"### Example 5: Grouping and Transforming Data\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"data = {\\n\"\n",
    "                         \"    'Category': ['A', 'A', 'B', 'B', 'A', 'B'],\\n\"\n",
    "                         \"    'Values': [10, 20, 15, 25, 10, 30]\\n\"\n",
    "                         \"}\\n\"\n",
    "                         \"df = pd.DataFrame(data)\\n\\n\"\n",
    "                         \"# Group by 'Category' and subtract the mean of 'Values' within each group\\n\"\n",
    "                         \"df['Adjusted Values'] = df.groupby('Category')['Values'].transform(lambda x: x - x.mean())\\n\\n\"\n",
    "                         \"print(df)\\n\"\n",
    "    ),\n",
    "    nbf.v4.new_markdown_cell(\"â€¢ Explanation: The DataFrame is grouped by Category, and the mean of Values within each group is subtracted from each value in that group. This operation is done using transform(), which returns a Series with the same shape as the original data.\"\n",
    "    ),\n",
    "    \n",
    "    # Summary\n",
    "    nbf.v4.new_markdown_cell(\"### Summary\\n\"\n",
    "                             \"â€¢ groupby() allows you to split your data into groups based on some criteria, perform operations on each group, and then combine the results.\\n\"\n",
    "                             \"â€¢ Aggregation functions like sum(), mean(), count(), etc., are commonly used with groupby.\\n\"\n",
    "                             \"â€¢ You can group by multiple columns, apply multiple aggregation functions, filter groups, or even transform data within groups.\\n\"\n",
    "                             \"â€¢ groupby() is essential for data analysis tasks where you need to summarize or manipulate data based on specific groupings.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add cells to the notebook\n",
    "nb.cells.extend(cells)\n",
    "\n",
    "# Save the notebook to a file\n",
    "with open('groupby.ipynb', 'w', encoding='utf-8') as f:\n",
    "    nbf.write(nb, f)\n",
    "\n",
    "print(\"Notebook 'pandas_groupby_example.ipynb' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b3d0fd-f37b-4b6c-857d-8d2257c63658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 'pandas_map.ipynb' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import nbformat as nbf\n",
    "\n",
    "# Create a new notebook\n",
    "nb = nbf.v4.new_notebook()\n",
    "\n",
    "# Define the content of the notebook in Markdown and code cells\n",
    "cells = [\n",
    "    # Title and Introduction\n",
    "    nbf.v4.new_markdown_cell(\"# pandas.DataFrame.map\\n\"\n",
    "                             \"The pandas.DataFrame.map function is a powerful tool for element-wise operations on a Series (not directly on a DataFrame, though similar operations can be done on DataFrame columns). It is used to map or substitute each value in a Series using a mapping correspondence (a dictionary, a function, or a Series).\"\n",
    "    ),\n",
    "    \n",
    "    # Basic Concept\n",
    "    nbf.v4.new_markdown_cell(\"## 1. Basic Concept\\n\"\n",
    "                             \"â€¢ **Series.map** is used for mapping values in a Series from one set of values to another based on a provided mapping.\\n\"\n",
    "                             \"â€¢ This is often used for tasks like replacing values, applying functions to each element, or using a dictionary to transform the data.\"\n",
    "    ),\n",
    "    \n",
    "    # Syntax\n",
    "    nbf.v4.new_markdown_cell(\"## 2. Syntax\\n\\n\"\n",
    "                             \"```python\\n\"\n",
    "                             \"Series.map(arg, na_action=None)\\n\"\n",
    "                             \"```\\n\"\n",
    "                             \"â€¢ **arg**: This can be a function, dictionary, or Series. It defines the mapping correspondence.\\n\"\n",
    "                             \"  - Function: A function to apply to each element of the Series.\\n\"\n",
    "                             \"  - Dictionary/Series: A mapping of values to new values.\\n\"\n",
    "                             \"â€¢ **na_action**: This can be either None or 'ignore'. If set to 'ignore', it leaves NaN values as NaN.\"\n",
    "    ),\n",
    "    \n",
    "    # Examples\n",
    "    nbf.v4.new_markdown_cell(\"## 3. Examples\\n\\n\"\n",
    "                             \"### Example 1: Mapping Using a Dictionary\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"import pandas as pd\\n\\n\"\n",
    "                         \"# Sample DataFrame\\n\"\n",
    "                         \"data = {\\n\"\n",
    "                         \"    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\\n\"\n",
    "                         \"    'Temperature': [75, 85, 60, 90, 100]\\n\"\n",
    "                         \"}\\n\"\n",
    "                         \"df = pd.DataFrame(data)\\n\\n\"\n",
    "                         \"# Mapping cities to states using a dictionary\\n\"\n",
    "                         \"city_to_state = {\\n\"\n",
    "                         \"    'New York': 'NY',\\n\"\n",
    "                         \"    'Los Angeles': 'CA',\\n\"\n",
    "                         \"    'Chicago': 'IL',\\n\"\n",
    "                         \"    'Houston': 'TX',\\n\"\n",
    "                         \"    'Phoenix': 'AZ'\\n\"\n",
    "                         \"}\\n\\n\"\n",
    "                         \"# Apply map function to 'City' column\\n\"\n",
    "                         \"df['State'] = df['City'].map(city_to_state)\\n\\n\"\n",
    "                         \"print(df)\\n\"\n",
    "    ),\n",
    "    nbf.v4.new_markdown_cell(\"â€¢ **Explanation**:\\n\"\n",
    "                             \"  - The `map()` function is applied to the 'City' column, using the `city_to_state` dictionary to map each city to its corresponding state.\\n\"\n",
    "                             \"  - A new column 'State' is created in the DataFrame containing the mapped state values.\"\n",
    "    ),\n",
    "    \n",
    "    # Example 2\n",
    "    nbf.v4.new_markdown_cell(\"### Example 2: Applying a Function to Each Element\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"# Apply a lambda function to convert Fahrenheit to Celsius\\n\"\n",
    "                         \"df['Temperature_Celsius'] = df['Temperature'].map(lambda x: (x - 32) * 5.0/9.0)\\n\\n\"\n",
    "                         \"print(df)\\n\"\n",
    "    ),\n",
    "    nbf.v4.new_markdown_cell(\"â€¢ **Explanation**:\\n\"\n",
    "                             \"  - The `map()` function is used here to apply a lambda function to each value in the 'Temperature' column.\\n\"\n",
    "                             \"  - The lambda function converts the temperature from Fahrenheit to Celsius, and the result is stored in a new column 'Temperature_Celsius'.\"\n",
    "    ),\n",
    "    \n",
    "    # Example 3\n",
    "    nbf.v4.new_markdown_cell(\"### Example 3: Handling Missing Mappings\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"# Adding a new city that is not in the mapping dictionary\\n\"\n",
    "                         \"df.loc[len(df.index)] = ['San Francisco', 65, None, None]\\n\\n\"\n",
    "                         \"# Mapping cities to states with NaN handling\\n\"\n",
    "                         \"df['State'] = df['City'].map(city_to_state)\\n\\n\"\n",
    "                         \"print(df)\\n\"\n",
    "    ),\n",
    "    nbf.v4.new_markdown_cell(\"â€¢ **Explanation**:\\n\"\n",
    "                             \"  - A new city 'San Francisco' is added to the DataFrame, but it is not included in the `city_to_state` dictionary.\\n\"\n",
    "                             \"  - When `map()` is called, it cannot find a match for 'San Francisco', so it assigns NaN to the 'State' column for that row.\\n\"\n",
    "                             \"  - `map()` naturally handles missing mappings by assigning NaN to unmatched values.\"\n",
    "    ),\n",
    "    \n",
    "    # Example 4\n",
    "    nbf.v4.new_markdown_cell(\"### Example 4: Mapping with a Series\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"# Creating a Series for mapping\\n\"\n",
    "                         \"state_population = pd.Series({\\n\"\n",
    "                         \"    'NY': 19.45,\\n\"\n",
    "                         \"    'CA': 39.51,\\n\"\n",
    "                         \"    'IL': 12.67,\\n\"\n",
    "                         \"    'TX': 28.7,\\n\"\n",
    "                         \"    'AZ': 7.28\\n\"\n",
    "                         \"}, name='Population_Millions')\\n\\n\"\n",
    "                         \"# Map states to their populations\\n\"\n",
    "                         \"df['Population_Millions'] = df['State'].map(state_population)\\n\\n\"\n",
    "                         \"print(df)\\n\"\n",
    "    ),\n",
    "    nbf.v4.new_markdown_cell(\"â€¢ **Explanation**:\\n\"\n",
    "                             \"  - A Series `state_population` is created, where the index represents the state abbreviations, and the values represent the population in millions.\\n\"\n",
    "                             \"  - The `map()` function maps the state abbreviations in the 'State' column to their corresponding population values.\\n\"\n",
    "                             \"  - The resulting population values are stored in a new column 'Population_Millions'.\"\n",
    "    ),\n",
    "    \n",
    "    # Summary\n",
    "    nbf.v4.new_markdown_cell(\"### Summary\\n\"\n",
    "                             \"â€¢ `map()` is mainly used with pandas Series to perform element-wise transformations based on a dictionary, Series, or function.\\n\"\n",
    "                             \"â€¢ It is commonly used to replace values, apply functions, and map values based on another Series or dictionary.\\n\"\n",
    "                             \"â€¢ **Handling missing values**: If a value in the Series is not found in the mapping, NaN is returned for that element.\\n\"\n",
    "                             \"â€¢ **Not applicable directly to DataFrames**: `map()` works on Series. For DataFrames, it can be applied to individual columns.\\n\\n\"\n",
    "                             \"The versatility of `map()` makes it a valuable tool in data manipulation and transformation tasks.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add cells to the notebook\n",
    "nb.cells.extend(cells)\n",
    "\n",
    "# Save the notebook to a file\n",
    "with open('pandas_map.ipynb', 'w',encoding='utf-8') as f:\n",
    "    nbf.write(nb, f)\n",
    "\n",
    "print(\"Notebook 'pandas_map.ipynb' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2738b037-ed47-4d08-bb1e-10b23f4db3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 'merge_example.ipynb' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import nbformat as nbf\n",
    "\n",
    "# Create a new notebook\n",
    "nb = nbf.v4.new_notebook()\n",
    "\n",
    "# Define the content of the notebook in Markdown and code cells\n",
    "cells = [\n",
    "    # Title and Introduction\n",
    "    nbf.v4.new_markdown_cell(\"# Creating DataFrames and Merging in pandas\\n\"\n",
    "                             \"In this notebook, we'll create two DataFrames and practice merging them using the `merge()` function in pandas. We'll cover various types of joins, including inner, left, right, and outer joins.\"\n",
    "    ),\n",
    "    \n",
    "    # Create DataFrames\n",
    "    nbf.v4.new_markdown_cell(\"## Creating DataFrames\\n\\n\"\n",
    "                             \"We'll start by creating two DataFrames: one for employees and one for departments.\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"import pandas as pd\\n\\n\"\n",
    "                         \"# Dataset 1: Employees\\n\"\n",
    "                         \"employees = pd.DataFrame({\\n\"\n",
    "                         \"    'EmployeeID': [1, 2, 3, 4, 5],\\n\"\n",
    "                         \"    'Name': ['John Doe', 'Jane Smith', 'Mike Brown', 'Emily Davis', 'Anna White'],\\n\"\n",
    "                         \"    'DepartmentID': [101, 102, 101, 103, 104],\\n\"\n",
    "                         \"    'Salary': [50000, 60000, 45000, 70000, 48000]\\n\"\n",
    "                         \"})\\n\\n\"\n",
    "                         \"# Dataset 2: Departments\\n\"\n",
    "                         \"departments = pd.DataFrame({\\n\"\n",
    "                         \"    'DepartmentID': [101, 102, 103, 105],\\n\"\n",
    "                         \"    'DepartmentName': ['HR', 'IT', 'Marketing', 'Sales']\\n\"\n",
    "                         \"})\\n\\n\"\n",
    "                         \"# Display the DataFrames\\n\"\n",
    "                         \"print(\\\"Employees DataFrame:\\\")\\n\"\n",
    "                         \"print(employees)\\n\"\n",
    "                         \"print(\\\"\\\\nDepartments DataFrame:\\\")\\n\"\n",
    "                         \"print(departments)\\n\"\n",
    "    ),\n",
    "    \n",
    "    # Merge Operations\n",
    "    nbf.v4.new_markdown_cell(\"## Example Merge Operations\\n\\n\"\n",
    "                             \"We can perform various merge operations using the `merge()` function. Here are some common types of joins:\"\n",
    "    ),\n",
    "    \n",
    "    # Inner Join\n",
    "    nbf.v4.new_markdown_cell(\"### Inner Join\\n\"\n",
    "                             \"Merging on `DepartmentID` to get only employees who have a matching department.\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"# Inner join\\n\"\n",
    "                         \"merged_inner = pd.merge(employees, departments, on='DepartmentID', how='inner')\\n\\n\"\n",
    "                         \"print(\\\"\\\\nInner Join Result:\\\")\\n\"\n",
    "                         \"print(merged_inner)\\n\"\n",
    "    ),\n",
    "    \n",
    "    # Left Join\n",
    "    nbf.v4.new_markdown_cell(\"### Left Join\\n\"\n",
    "                             \"Keeping all employees and adding department information where available.\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"# Left join\\n\"\n",
    "                         \"merged_left = pd.merge(employees, departments, on='DepartmentID', how='left')\\n\\n\"\n",
    "                         \"print(\\\"\\\\nLeft Join Result:\\\")\\n\"\n",
    "                         \"print(merged_left)\\n\"\n",
    "    ),\n",
    "    \n",
    "    # Right Join\n",
    "    nbf.v4.new_markdown_cell(\"### Right Join\\n\"\n",
    "                             \"Keeping all departments and adding employee information where available.\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"# Right join\\n\"\n",
    "                         \"merged_right = pd.merge(employees, departments, on='DepartmentID', how='right')\\n\\n\"\n",
    "                         \"print(\\\"\\\\nRight Join Result:\\\")\\n\"\n",
    "                         \"print(merged_right)\\n\"\n",
    "    ),\n",
    "    \n",
    "    # Outer Join\n",
    "    nbf.v4.new_markdown_cell(\"### Outer Join\\n\"\n",
    "                             \"Combining all employees and departments, regardless of whether they have matching data.\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"# Outer join\\n\"\n",
    "                         \"merged_outer = pd.merge(employees, departments, on='DepartmentID', how='outer')\\n\\n\"\n",
    "                         \"print(\\\"\\\\nOuter Join Result:\\\")\\n\"\n",
    "                         \"print(merged_outer)\\n\"\n",
    "    ),\n",
    "    \n",
    "    # Summary\n",
    "    nbf.v4.new_markdown_cell(\"## Summary\\n\"\n",
    "                             \"In this notebook, we demonstrated how to create DataFrames and perform various merge operations using the `merge()` function in pandas. We covered:\\n\"\n",
    "                             \"- **Inner Join**: Merges only rows with matching keys in both DataFrames.\\n\"\n",
    "                             \"- **Left Join**: Keeps all rows from the left DataFrame and adds matching rows from the right DataFrame.\\n\"\n",
    "                             \"- **Right Join**: Keeps all rows from the right DataFrame and adds matching rows from the left DataFrame.\\n\"\n",
    "                             \"- **Outer Join**: Combines all rows from both DataFrames, with NaN for missing matches.\\n\\n\"\n",
    "                             \"These operations are useful for combining datasets and performing relational data analysis.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add cells to the notebook\n",
    "nb.cells.extend(cells)\n",
    "\n",
    "# Save the notebook to a file\n",
    "with open('merge_example.ipynb', 'w',encoding='utf-8') as f:\n",
    "    nbf.write(nb, f)\n",
    "\n",
    "print(\"Notebook 'merge_example.ipynb' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a134c49-73e1-49a4-8c94-4403146740eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 'pivot_example.ipynb' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import nbformat as nbf\n",
    "\n",
    "# Create a new notebook\n",
    "nb = nbf.v4.new_notebook()\n",
    "\n",
    "# Define the content of the notebook in Markdown and code cells\n",
    "cells = [\n",
    "    # Title and Introduction\n",
    "    nbf.v4.new_markdown_cell(\"# Using pandas.DataFrame.pivot\\n\"\n",
    "                             \"The `pandas.DataFrame.pivot` function is a powerful tool for reshaping DataFrames. It transforms data from a long format to a wide format, which is useful for data analysis and reporting.\\n\\n\"\n",
    "                             \"In this notebook, we will explore how to use `pivot` to reorganize and summarize data. We will cover basic usage, handling missing data, reshaping data back, and using MultiIndex.\"\n",
    "    ),\n",
    "    \n",
    "    # Basic Concept\n",
    "    nbf.v4.new_markdown_cell(\"## Basic Concept\\n\\n\"\n",
    "                             \"`pandas.DataFrame.pivot` rearranges the data in your DataFrame by converting unique values from one column into new columns and organizing the data according to a given index and values.\\n\\n\"\n",
    "                             \"It is mainly used to reorganize and summarize data for better analysis.\"\n",
    "    ),\n",
    "    \n",
    "    # Syntax\n",
    "    nbf.v4.new_markdown_cell(\"## Syntax\\n\\n\"\n",
    "                             \"`DataFrame.pivot(index=None, columns=None, values=None)`\\n\\n\"\n",
    "                             \"- **index**: The column to use as the new DataFrameâ€™s index. If None, uses the existing index.\\n\"\n",
    "                             \"- **columns**: The column whose unique values will become the columns in the pivoted DataFrame.\\n\"\n",
    "                             \"- **values**: The column to fill the new DataFrame's values. If None, all remaining columns are used.\"\n",
    "    ),\n",
    "    \n",
    "    # Basic Example\n",
    "    nbf.v4.new_markdown_cell(\"## Basic Example\\n\\n\"\n",
    "                             \"Let's start with a simple example to understand how pivot works.\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"import pandas as pd\\n\\n\"\n",
    "                         \"# Create a simple DataFrame\\n\"\n",
    "                         \"data = {\\n\"\n",
    "                         \"    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02'],\\n\"\n",
    "                         \"    'City': ['New York', 'Los Angeles', 'New York', 'Los Angeles'],\\n\"\n",
    "                         \"    'Temperature': [32, 75, 30, 78],\\n\"\n",
    "                         \"    'Humidity': [80, 20, 85, 18]\\n\"\n",
    "                         \"}\\n\\n\"\n",
    "                         \"df = pd.DataFrame(data)\\n\"\n",
    "                         \"print(\\\"Original DataFrame:\\\")\\n\"\n",
    "                         \"print(df)\\n\\n\"\n",
    "                         \"# Pivot the DataFrame\\n\"\n",
    "                         \"pivot_df = df.pivot(index='Date', columns='City', values='Temperature')\\n\"\n",
    "                         \"print(\\\"\\\\nPivoted DataFrame:\\\")\\n\"\n",
    "                         \"print(pivot_df)\\n\"\n",
    "    ),\n",
    "    \n",
    "    # Pivot with Multiple Values\n",
    "    nbf.v4.new_markdown_cell(\"## Pivot with Multiple Values\\n\\n\"\n",
    "                             \"You can also pivot multiple columns by specifying a list of column names in the `values` parameter.\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"# Pivot with multiple values\\n\"\n",
    "                         \"pivot_df = df.pivot(index='Date', columns='City', values=['Temperature', 'Humidity'])\\n\"\n",
    "                         \"print(\\\"\\\\nPivoted DataFrame with multiple values:\\\")\\n\"\n",
    "                         \"print(pivot_df)\\n\"\n",
    "    ),\n",
    "    \n",
    "    # Handling Missing Data\n",
    "    nbf.v4.new_markdown_cell(\"## Handling Missing Data\\n\\n\"\n",
    "                             \"If your data contains combinations of index and columns that do not exist in the original DataFrame, the resulting pivoted DataFrame will contain NaN for those missing values.\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"# Add a row with a missing city\\n\"\n",
    "                         \"data_with_missing = {\\n\"\n",
    "                         \"    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03'],\\n\"\n",
    "                         \"    'City': ['New York', 'Los Angeles', 'New York', 'Los Angeles', 'New York'],\\n\"\n",
    "                         \"    'Temperature': [32, 75, 30, 78, 28],\\n\"\n",
    "                         \"    'Humidity': [80, 20, 85, 18, 90]\\n\"\n",
    "                         \"}\\n\\n\"\n",
    "                         \"df_missing = pd.DataFrame(data_with_missing)\\n\"\n",
    "                         \"print(\\\"\\\\nOriginal DataFrame with missing data:\\\")\\n\"\n",
    "                         \"print(df_missing)\\n\\n\"\n",
    "                         \"# Pivot the DataFrame\\n\"\n",
    "                         \"pivot_df_missing = df_missing.pivot(index='Date', columns='City', values='Temperature')\\n\"\n",
    "                         \"print(\\\"\\\\nPivoted DataFrame with missing data:\\\")\\n\"\n",
    "                         \"print(pivot_df_missing)\\n\"\n",
    "    ),\n",
    "    \n",
    "    # Reshaping Back\n",
    "    nbf.v4.new_markdown_cell(\"## Reshaping Back: From Pivoted DataFrame to Original\\n\\n\"\n",
    "                             \"If you need to reshape the pivoted DataFrame back to its original long format, you can use the `pandas.DataFrame.melt` function.\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"# Reshape back using melt\\n\"\n",
    "                         \"melted_df = pivot_df_missing.reset_index().melt(id_vars='Date', value_name='Temperature')\\n\"\n",
    "                         \"print(\\\"\\\\nMelted DataFrame:\\\")\\n\"\n",
    "                         \"print(melted_df)\\n\"\n",
    "    ),\n",
    "    \n",
    "    # Pivoting with MultiIndex\n",
    "    nbf.v4.new_markdown_cell(\"## Pivoting with MultiIndex\\n\\n\"\n",
    "                             \"You can create a pivoted DataFrame with multiple index levels (MultiIndex) by using multiple columns in the `index` parameter.\"\n",
    "    ),\n",
    "    nbf.v4.new_code_cell(\"# Create a DataFrame with more complex data\\n\"\n",
    "                         \"data_multi = {\\n\"\n",
    "                         \"    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03'],\\n\"\n",
    "                         \"    'City': ['New York', 'Los Angeles', 'New York', 'Los Angeles', 'New York'],\\n\"\n",
    "                         \"    'Type': ['Temperature', 'Temperature', 'Temperature', 'Temperature', 'Temperature'],\\n\"\n",
    "                         \"    'Value': [32, 75, 30, 78, 28]\\n\"\n",
    "                         \"}\\n\\n\"\n",
    "                         \"df_multi = pd.DataFrame(data_multi)\\n\"\n",
    "                         \"print(\\\"\\\\nOriginal DataFrame with multiple index levels:\\\")\\n\"\n",
    "                         \"print(df_multi)\\n\\n\"\n",
    "                         \"# Pivot with MultiIndex\\n\"\n",
    "                         \"pivot_df_multi = df_multi.pivot(index=['Date', 'Type'], columns='City', values='Value')\\n\"\n",
    "                         \"print(\\\"\\\\nPivoted DataFrame with MultiIndex:\\\")\\n\"\n",
    "                         \"print(pivot_df_multi)\\n\"\n",
    "    ),\n",
    "    \n",
    "    # Pivoting without Aggregation\n",
    "    nbf.v4.new_markdown_cell(\"## Pivoting without Aggregation: Difference from pivot_table\\n\\n\"\n",
    "                             \"Unlike `pivot_table`, which performs aggregation (e.g., sum, mean), `pivot` does not perform any aggregation. It simply reshapes the data.\"\n",
    "    ),\n",
    "    \n",
    "    # Summary\n",
    "    nbf.v4.new_markdown_cell(\"## Summary\\n\\n\"\n",
    "                             \"The `pandas.DataFrame.pivot` function is used to reshape DataFrames by transforming data into a wide format, making it easier to analyze and report. Key points include:\\n\\n\"\n",
    "                             \"- **Parameters**:\\n\"\n",
    "                             \"  - **index**: Determines the new index for the pivoted DataFrame.\\n\"\n",
    "                             \"  - **columns**: Defines the new columns based on unique values from this column.\\n\"\n",
    "                             \"  - **values**: Specifies which column's values to use for filling the new DataFrame.\\n\"\n",
    "                             \"- **Handling Missing Data**: The resulting pivoted DataFrame will show NaN for missing values.\\n\"\n",
    "                             \"- **Reshaping**: Use `melt` to reshape data back to its long format.\\n\"\n",
    "                             \"- **MultiIndex**: Supports creating pivoted DataFrames with hierarchical indices.\\n\\n\"\n",
    "                             \"Understanding how to use `pivot` effectively can help you organize and analyze data more efficiently, especially when dealing with complex datasets.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add cells to the notebook\n",
    "nb.cells.extend(cells)\n",
    "\n",
    "# Save the notebook to a file\n",
    "with open('pivot_example.ipynb', 'w',encoding='utf-8') as f:\n",
    "    nbf.write(nb, f)\n",
    "\n",
    "print(\"Notebook 'pivot_example.ipynb' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418e28b8-2769-49c5-8b5f-1af6501a77ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 'melt_example.ipynb' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import nbformat as nbf\n",
    "\n",
    "# Create a new notebook object\n",
    "nb = nbf.v4.new_notebook()\n",
    "\n",
    "# List of cells to add to the notebook\n",
    "cells = [\n",
    "    nbf.v4.new_markdown_cell(\"# pandas.melt\"),\n",
    "    nbf.v4.new_markdown_cell(\"pandas.melt is a powerful function in pandas that allows you to transform or reshape a DataFrame from a wide format to a long format. This is often used when you need to normalize your data for easier analysis or to prepare it for specific types of visualizations or operations.\"),\n",
    "    \n",
    "    nbf.v4.new_markdown_cell(\"## 1. Basic Concept of pandas.melt\"),\n",
    "    nbf.v4.new_markdown_cell(\"* **Wide format:** Data is spread across multiple columns. Each column represents a different variable.\\n\"\n",
    "                             \"* **Long format:** Data is condensed into fewer columns, with one column identifying the variable type and another column holding the value.\\n\"\n",
    "                             \"pandas.melt essentially unpivots the DataFrame, making it longer by turning multiple columns into rows.\"),\n",
    "    \n",
    "    nbf.v4.new_markdown_cell(\"## 2. Syntax\"),\n",
    "    nbf.v4.new_code_cell(\"pandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)\"),\n",
    "    nbf.v4.new_markdown_cell(\"* **frame:** The DataFrame to melt.\\n\"\n",
    "                             \"* **id_vars:** Columns to use as identifiers (i.e., columns that should remain fixed).\\n\"\n",
    "                             \"* **value_vars:** Columns to unpivot (i.e., columns to convert into rows).\\n\"\n",
    "                             \"* **var_name:** Name to use for the variable column. If not specified, uses the original column name.\\n\"\n",
    "                             \"* **value_name:** Name to use for the value column.\\n\"\n",
    "                             \"* **col_level:** If columns are multi-indexed, this specifies which level to melt.\\n\"\n",
    "                             \"* **ignore_index:** If True, the index is reset in the result.\"),\n",
    "    \n",
    "    nbf.v4.new_markdown_cell(\"## 3. Basic Example of pandas.melt\"),\n",
    "    nbf.v4.new_code_cell(\"import pandas as pd\\n\\n\"\n",
    "                         \"# Create a simple DataFrame\\n\"\n",
    "                         \"data = {\\n\"\n",
    "                         \"    'Date': ['2023-01-01', '2023-01-02'],\\n\"\n",
    "                         \"    'New York': [32, 30],\\n\"\n",
    "                         \"    'Los Angeles': [75, 78],\\n\"\n",
    "                         \"    'Chicago': [28, 27]\\n\"\n",
    "                         \"}\\n\\n\"\n",
    "                         \"df = pd.DataFrame(data)\\n\"\n",
    "                         \"print('Original DataFrame:')\\n\"\n",
    "                         \"print(df)\\n\\n\"\n",
    "                         \"# Melt the DataFrame\\n\"\n",
    "                         \"melted_df = pd.melt(df, id_vars=['Date'], value_vars=['New York', 'Los Angeles', 'Chicago'],\\n\"\n",
    "                         \"                    var_name='City', value_name='Temperature')\\n\"\n",
    "                         \"print('\\\\nMelted DataFrame:')\\n\"\n",
    "                         \"print(melted_df)\"),\n",
    "    nbf.v4.new_markdown_cell(\"* **Explanation:**\\n\"\n",
    "                             \"  * **id_vars:** The Date column remains fixed.\\n\"\n",
    "                             \"  * **value_vars:** The New York, Los Angeles, and Chicago columns are unpivoted.\\n\"\n",
    "                             \"  * **var_name:** The unpivoted column names are stored in the City column.\\n\"\n",
    "                             \"  * **value_name:** The values from the unpivoted columns are stored in the Temperature column.\"),\n",
    "    \n",
    "    nbf.v4.new_markdown_cell(\"## 4. Melt with Default Parameters\"),\n",
    "    nbf.v4.new_code_cell(\"# Melt without specifying value_vars\\n\"\n",
    "                         \"melted_df_default = pd.melt(df, id_vars=['Date'])\\n\"\n",
    "                         \"print('\\\\nMelted DataFrame with default value_vars:')\\n\"\n",
    "                         \"print(melted_df_default)\"),\n",
    "    nbf.v4.new_markdown_cell(\"* **Explanation:**\\n\"\n",
    "                             \"  * By default, melt uses all columns except id_vars as value_vars.\\n\"\n",
    "                             \"  * The variable column (default name) holds the column names, and the value column holds the data.\"),\n",
    "    \n",
    "    nbf.v4.new_markdown_cell(\"## 5. Changing var_name and value_name\"),\n",
    "    nbf.v4.new_code_cell(\"# Melt with custom var_name and value_name\\n\"\n",
    "                         \"melted_df_custom = pd.melt(df, id_vars=['Date'], var_name='Location', value_name='Temp')\\n\"\n",
    "                         \"print('\\\\nMelted DataFrame with custom var_name and value_name:')\\n\"\n",
    "                         \"print(melted_df_custom)\"),\n",
    "    nbf.v4.new_markdown_cell(\"* **Explanation:**\\n\"\n",
    "                             \"  * The variable column is renamed to Location.\\n\"\n",
    "                             \"  * The value column is renamed to Temp.\"),\n",
    "    \n",
    "    nbf.v4.new_markdown_cell(\"## 6. Using pandas.melt with MultiIndex Columns\"),\n",
    "    nbf.v4.new_code_cell(\"# Create a DataFrame with MultiIndex columns\\n\"\n",
    "                         \"arrays = [['Temperature', 'Temperature', 'Humidity', 'Humidity'],\\n\"\n",
    "                         \"          ['New York', 'Los Angeles', 'New York', 'Los Angeles']]\\n\"\n",
    "                         \"index = pd.MultiIndex.from_arrays(arrays, names=('Type', 'City'))\\n\\n\"\n",
    "                         \"df_multi = pd.DataFrame([[32, 75, 80, 20], [30, 78, 85, 18]], columns=index, index=['2023-01-01', '2023-01-02'])\\n\"\n",
    "                         \"print('\\\\nOriginal DataFrame with MultiIndex columns:')\\n\"\n",
    "                         \"print(df_multi)\\n\\n\"\n",
    "                         \"# Melt the MultiIndex DataFrame\\n\"\n",
    "                         \"melted_df_multi = pd.melt(df_multi.reset_index(), id_vars=['index'], col_level=1)\\n\"\n",
    "                         \"print('\\\\nMelted DataFrame with MultiIndex columns:')\\n\"\n",
    "                         \"print(melted_df_multi)\"),\n",
    "    nbf.v4.new_markdown_cell(\"* **Explanation:**\\n\"\n",
    "                             \"  * col_level=1 specifies that the second level of the columns (City) is melted.\\n\"\n",
    "                             \"  * The Type level of the MultiIndex is not melted and remains as part of the new column headers.\"),\n",
    "    \n",
    "    nbf.v4.new_markdown_cell(\"## 7. Ignoring Index with ignore_index\"),\n",
    "    nbf.v4.new_code_cell(\"# Melt with ignore_index\\n\"\n",
    "                         \"melted_df_ignore_index = pd.melt(df, id_vars=['Date'], ignore_index=False)\\n\"\n",
    "                         \"print('\\\\nMelted DataFrame with original index retained:')\\n\"\n",
    "                         \"print(melted_df_ignore_index)\"),\n",
    "    nbf.v4.new_markdown_cell(\"* **Explanation:**\\n\"\n",
    "                             \"  * The original index from the DataFrame is retained in the melted DataFrame.\"),\n",
    "    \n",
    "    nbf.v4.new_markdown_cell(\"## 8. When to Use pandas.melt\"),\n",
    "    nbf.v4.new_markdown_cell(\"* **Normalization:** If you have data in a wide format (multiple columns for variables) and you need to normalize it for analysis.\\n\"\n",
    "                             \"* **Visualization:** Certain visualizations or statistical analyses require data in a long format.\\n\"\n",
    "                             \"* **Data Preparation:** Prepares data for certain types of operations, like grouping, merging, or applying functions that require long-format data.\"),\n",
    "    \n",
    "    nbf.v4.new_markdown_cell(\"## Summary\"),\n",
    "    nbf.v4.new_markdown_cell(\"* **pandas.melt** is used to reshape DataFrames from wide to long format.\\n\"\n",
    "                             \"* **Key Concepts:**\\n\"\n",
    "                             \"  * **id_vars:** Columns that remain fixed in the output DataFrame.\\n\"\n",
    "                             \"  * **value_vars:** Columns to unpivot into rows.\\n\"\n",
    "                             \"  * **var_name** and **value_name:** Custom names for the resulting columns.\\n\"\n",
    "                             \"  * **col_level:** Used for MultiIndex columns to specify which level to melt.\\n\"\n",
    "                             \"  * **ignore_index:** Determines whether to reset the index in the resulting DataFrame.\\n\"\n",
    "                             \"* **Applications:**\\n\"\n",
    "                             \"  * Normalizing data.\\n\"\n",
    "                             \"  * Preparing data for analysis, visualization, or further processing.\\n\"\n",
    "                             \"Understanding how to use pandas.melt effectively can help you manipulate and analyze your data more efficiently, particularly when dealing with complex datasets that need to be reshaped for specific tasks.\")\n",
    "]\n",
    "\n",
    "# Add the cells to the notebook\n",
    "nb['cells'] = cells\n",
    "\n",
    "# Write the notebook to a file\n",
    "with open(\"melt_example.ipynb\", \"w\", encoding=\"utf-8\") as f:\n",
    "    nbf.write(nb, f)\n",
    "    \n",
    "print(\"Notebook 'melt_example.ipynb' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a24ef2-a573-4a44-ab42-6b73a9c14210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
